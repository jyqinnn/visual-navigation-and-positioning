# visual-navigation-and-positioning     

  This is the implementation of the paper:     
  
  A Survey on Visual Navigation and Positioning for Autonomous Unmanned Underwater Vehicles

# Table of Contents     

visual-inertial methods     

* *OKVIS*

OKVIS: Open Keyframe-based Visual-Inertial SLAM [1]     

from https://github.com/ethz-asl/okvis     

* *ORB-SLAM3*     

ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM [2]     

from https://github.com/UZ-SLAMLab/ORB_SLAM3    

* *VINet*       

VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning Problem.





# Reference
[1] Stefan Leutenegger, Simon Lynen, Michael Bosse, Roland Siegwart and Paul Timothy Furgale. Keyframe-based visual–inertial odometry using nonlinear optimization. The International Journal of Robotics Research, 2015.     

[2] Carlos Campos, Richard Elvira, Juan J. Gómez Rodríguez, José M. M. Montiel and Juan D. Tardós, ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM, IEEE Transactions on Robotics 37(6):1874-1890, Dec. 2021.     

[3] Clark, Ronald, et al. "VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning Problem." AAAI. 2017.

